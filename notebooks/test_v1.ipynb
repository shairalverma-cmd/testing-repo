{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc246ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil # For sorting files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55b6f5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.7.4.5)\n",
      "Requirement already satisfied: bleach in c:\\users\\laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (6.3.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2025.11.12)\n",
      "Requirement already satisfied: charset-normalizer in c:\\users\\laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (3.4.4)\n",
      "Requirement already satisfied: idna in c:\\users\\laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (3.11)\n",
      "Requirement already satisfied: protobuf in c:\\users\\laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (6.33.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\users\\laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (80.9.0)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in c:\\users\\laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (4.67.1)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (0.5.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\laptop\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a135e7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kaggle API 1.7.4.5\n"
     ]
    }
   ],
   "source": [
    "!kaggle --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61f5ee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../data/user2\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cd02b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dogs-vs-cats-redux-kernels-edition.zip to data/user2\n",
      "[Errno 28] No space left on device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/814M [00:00<?, ?B/s]\n",
      "  0%|          | 1.00M/814M [00:01<13:41, 1.04MB/s]\n",
      "  2%|▏         | 17.0M/814M [00:01<00:38, 21.5MB/s]\n",
      "  3%|▎         | 25.0M/814M [00:01<00:37, 22.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dogs-vs-cats-redux-kernels-edition.zip to ../data/user2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/814M [00:00<?, ?B/s]\n",
      "  0%|          | 1.00M/814M [00:00<03:59, 3.55MB/s]\n",
      "  2%|▏         | 20.0M/814M [00:00<00:12, 66.5MB/s]\n",
      "  5%|▍         | 39.0M/814M [00:00<00:07, 108MB/s] \n",
      "  7%|▋         | 61.0M/814M [00:00<00:05, 144MB/s]\n",
      " 10%|▉         | 79.0M/814M [00:00<00:04, 157MB/s]\n",
      " 12%|█▏        | 97.0M/814M [00:00<00:04, 162MB/s]\n",
      " 14%|█▍        | 117M/814M [00:00<00:04, 175MB/s] \n",
      " 17%|█▋        | 135M/814M [00:01<00:14, 50.6MB/s]\n",
      " 19%|█▉        | 153M/814M [00:01<00:10, 65.0MB/s]\n",
      " 21%|██        | 171M/814M [00:02<00:08, 81.2MB/s]\n",
      " 23%|██▎       | 187M/814M [00:02<00:07, 92.7MB/s]\n",
      " 26%|██▌       | 211M/814M [00:02<00:05, 121MB/s] \n",
      " 28%|██▊       | 229M/814M [00:02<00:04, 126MB/s]\n",
      " 31%|███       | 250M/814M [00:02<00:04, 145MB/s]\n",
      " 33%|███▎      | 272M/814M [00:02<00:03, 163MB/s]\n",
      " 36%|███▌      | 291M/814M [00:02<00:03, 150MB/s]\n",
      " 38%|███▊      | 308M/814M [00:04<00:12, 41.8MB/s]\n",
      " 41%|████      | 333M/814M [00:04<00:08, 59.9MB/s]\n",
      " 44%|████▍     | 356M/814M [00:04<00:06, 78.8MB/s]\n",
      " 47%|████▋     | 380M/814M [00:04<00:04, 101MB/s] \n",
      " 49%|████▉     | 400M/814M [00:04<00:03, 114MB/s]\n",
      " 52%|█████▏    | 419M/814M [00:04<00:03, 113MB/s]\n",
      " 54%|█████▎    | 436M/814M [00:04<00:03, 115MB/s]\n",
      " 55%|█████▌    | 451M/814M [00:04<00:03, 118MB/s]\n",
      " 57%|█████▋    | 465M/814M [00:05<00:08, 43.5MB/s]\n",
      " 59%|█████▊    | 476M/814M [00:06<00:08, 40.5MB/s]\n",
      " 61%|██████    | 495M/814M [00:06<00:05, 55.9MB/s]\n",
      " 63%|██████▎   | 511M/814M [00:06<00:04, 69.2MB/s]\n",
      " 65%|██████▌   | 530M/814M [00:06<00:03, 88.1MB/s]\n",
      " 67%|██████▋   | 546M/814M [00:06<00:02, 102MB/s] \n",
      " 69%|██████▉   | 561M/814M [00:06<00:02, 103MB/s]\n",
      " 71%|███████   | 575M/814M [00:06<00:02, 104MB/s]\n",
      " 72%|███████▏  | 588M/814M [00:07<00:03, 59.8MB/s]\n",
      " 74%|███████▎  | 598M/814M [00:08<00:05, 39.9MB/s]\n",
      " 75%|███████▍  | 610M/814M [00:08<00:04, 48.8MB/s]\n",
      " 76%|███████▌  | 620M/814M [00:08<00:03, 55.8MB/s]\n",
      " 78%|███████▊  | 636M/814M [00:08<00:02, 73.3MB/s]\n",
      " 80%|███████▉  | 647M/814M [00:08<00:02, 74.2MB/s]\n",
      " 81%|████████▏ | 663M/814M [00:08<00:01, 92.3MB/s]\n",
      " 84%|████████▍ | 682M/814M [00:08<00:01, 115MB/s] \n",
      " 86%|████████▋ | 702M/814M [00:08<00:00, 136MB/s]\n",
      " 88%|████████▊ | 718M/814M [00:08<00:00, 129MB/s]\n",
      " 91%|█████████ | 742M/814M [00:09<00:00, 158MB/s]\n",
      " 93%|█████████▎| 759M/814M [00:10<00:01, 36.2MB/s]\n",
      " 95%|█████████▍| 772M/814M [00:10<00:01, 42.7MB/s]\n",
      " 96%|█████████▋| 784M/814M [00:10<00:00, 45.4MB/s]\n",
      " 98%|█████████▊| 794M/814M [00:11<00:00, 49.3MB/s]\n",
      " 99%|█████████▊| 803M/814M [00:11<00:00, 54.6MB/s]\n",
      "100%|█████████▉| 813M/814M [00:11<00:00, 60.3MB/s]\n",
      "100%|██████████| 814M/814M [00:11<00:00, 75.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Download competition dataset into that folder\n",
    "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition -p ../data/user2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c28f545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# unzip main file\n",
    "main_zip = Path(\"../data/user2/dogs-vs-cats-redux-kernels-edition.zip\")\n",
    "with zipfile.ZipFile(main_zip, 'r') as z:\n",
    "    z.extractall(\"../data/user2\")\n",
    "\n",
    "# unzip training set\n",
    "train_zip = Path(\"../data/user2/train.zip\")\n",
    "with zipfile.ZipFile(train_zip, 'r') as z:\n",
    "    z.extractall(\"../data/user2/train_images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0dc18445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting User 2's images...\n",
      "Found 25000 files in train_images\n",
      "Image sorting complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Sorting User 2's images...\")\n",
    "\n",
    "RAW_DATA_DIR = '../data/user2/train_images/train'\n",
    "SORTED_DATA_DIR = '../data/user2/train_sorted'\n",
    "\n",
    "# Create class folders if they don't exist\n",
    "os.makedirs(os.path.join(SORTED_DATA_DIR, 'cats'), exist_ok=True)\n",
    "os.makedirs(os.path.join(SORTED_DATA_DIR, 'dogs'), exist_ok=True)\n",
    "\n",
    "# List files\n",
    "all_files = os.listdir(RAW_DATA_DIR)\n",
    "print(f\"Found {len(all_files)} files in train_images\")\n",
    "\n",
    "for f in all_files:\n",
    "    src = os.path.join(RAW_DATA_DIR, f)\n",
    "\n",
    "    # Skip directories\n",
    "    if os.path.isdir(src):\n",
    "        continue\n",
    "\n",
    "    fname = f.lower()  # make case-insensitive\n",
    "\n",
    "    if fname.startswith('cat'):\n",
    "        shutil.move(src, os.path.join(SORTED_DATA_DIR, 'cats', f))\n",
    "    elif fname.startswith('dog'):\n",
    "        shutil.move(src, os.path.join(SORTED_DATA_DIR, 'dogs', f))\n",
    "    else:\n",
    "        print(\"⚠️ Unknown file skipped:\", f)\n",
    "\n",
    "print(\"Image sorting complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f44ea98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (128, 128)\n",
    "BATCH_SIZE = 32\n",
    "DATA_DIR_USER2 = SORTED_DATA_DIR # Use the new sorted directory\n",
    "\n",
    "datagen_u2 = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "train_generator_u2 = datagen_u2.flow_from_directory(\n",
    "    DATA_DIR_USER2,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary', # Changed to binary\n",
    "    subset='training'\n",
    ")\n",
    "validation_generator_u2 = datagen_u2.flow_from_directory(\n",
    "    DATA_DIR_USER2,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary', # Changed to binary\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0a7d4c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model_v1 on User 2's validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model_v1.h5\n",
      "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 189ms/step - accuracy: 0.7066 - loss: 0.5699\n",
      "Saved test_v1_user2.json to results/\n",
      "✅ Phase 2, Step 4: Testing of model_v1 complete.\n"
     ]
    }
   ],
   "source": [
    "# --- ML Code: Test Model V1 ---\n",
    "print(\"Testing model_v1 on User 2's validation data...\")\n",
    "try:\n",
    "    model_v1 = tf.keras.models.load_model('../models/model_v1.h5')\n",
    "    print(\"Loaded model_v1.h5\")\n",
    "\n",
    "    results_v1_on_u2_data = model_v1.evaluate(validation_generator_u2)\n",
    "\n",
    "    test_metrics_v1_u2 = {\n",
    "        'test_loss': results_v1_on_u2_data[0],\n",
    "        'test_accuracy': results_v1_on_u2_data[1]\n",
    "    }\n",
    "except Exception as e:\n",
    "    print(f\"Error testing model_v1: {e}\")\n",
    "    test_metrics_v1_u2 = {'test_loss': 'Error', 'test_accuracy': 'Error'}\n",
    "\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "\n",
    "# Save test results\n",
    "with open('../results/test_v1_user2.json', 'w') as f:\n",
    "    json.dump(test_metrics_v1_u2, f, indent=4)\n",
    "\n",
    "print(\"Saved test_v1_user2.json to results/\")\n",
    "\n",
    "print(\"✅ Phase 2, Step 4: Testing of model_v1 complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
